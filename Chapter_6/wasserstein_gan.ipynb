{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wasserstein GAN (W-GAN)\n",
    "\n",
    "Originally proposed by [Arjovsky et al.](https://arxiv.org/pdf/1701.07875.pdf) is their work titled Unsupervised Representation Learning With Deep Convolutions Generative Adversarial Networks. This network uses a basic implementation where generator and discriminator models use convolutional layers, batch normalization and Upsampling.\n",
    "This notebook trains both networks using ADAM optimizer to play the minimax game. We showcase the effectiveness using MNIST digit generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PacktPublishing/Hands-On-Generative-AI-with-Python-and-TensorFlow-2/blob/master/Chapter_6/wasserstein_gan.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gan_utils import build_critic\n",
    "from gan_utils import build_dc_generator\n",
    "from gan_utils import sample_images\n",
    "from gan_utils import wasserstein_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W-GAN Training Loop\n",
    "- As proposed in the original paper\n",
    "- Train critic using a mix of fake and real samples\n",
    "- Calculate discriminator loss\n",
    "- Train the critic 5 times per training cycle of the generator\n",
    "- Use Wasserstein_loss for both generator and discriminators\n",
    "- Fix the discriminator and train generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator=None,discriminator=None,gan_model=None,\n",
    "          epochs=1000, discriminator_cycles=5, batch_size=128, sample_interval=50,\n",
    "          z_dim=100,clip_value = 0.01):\n",
    "    # Load MNIST train samples\n",
    "    (X_train, _), (_, _) = datasets.mnist.load_data()\n",
    "\n",
    "    # Rescale -1 to 1\n",
    "    X_train = X_train / 127.5 - 1\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "    # Prepare GAN output labels\n",
    "    real_y = -np.ones((batch_size, 1))\n",
    "    fake_y = np.ones((batch_size, 1))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # train disriminator\n",
    "        for _ in range(discriminator_cycles):\n",
    "            # pick random real samples from X_train\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            real_imgs = X_train[idx]\n",
    "\n",
    "            # pick random noise samples (z) from a normal distribution\n",
    "            noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "            # use generator model to generate output samples\n",
    "            fake_imgs = generator.predict(noise)\n",
    "\n",
    "            # calculate discriminator loss on real samples\n",
    "            disc_loss_real = discriminator.train_on_batch(real_imgs, real_y)\n",
    "\n",
    "            # calculate discriminator loss on fake samples\n",
    "            disc_loss_fake = discriminator.train_on_batch(fake_imgs, fake_y)\n",
    "\n",
    "            # overall discriminator loss\n",
    "            discriminator_loss = 0.5 * np.add(disc_loss_real, disc_loss_fake)\n",
    "            \n",
    "            # clip weights to ensure adherance to model constraints in EM space\n",
    "            # Clip critic weights\n",
    "            for l in discriminator.layers:\n",
    "                weights = l.get_weights()\n",
    "                weights = [np.clip(w, -clip_value, clip_value) for w in weights]\n",
    "                l.set_weights(weights)\n",
    "        \n",
    "        #train generator\n",
    "        # pick random noise samples (z) from a normal distribution\n",
    "        noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "\n",
    "        # use trained discriminator to improve generator\n",
    "        gen_loss = gan_model.train_on_batch(noise, real_y)\n",
    "\n",
    "        # training updates\n",
    "        print (\"%d [Discriminator loss: %f] [Generator loss: %f]\" % (epoch,\n",
    "                                                                     1 - discriminator_loss[0], \n",
    "                                                                     1 - gen_loss[0]))\n",
    "\n",
    "        # If at save interval => save generated image samples\n",
    "        if epoch % sample_interval == 0:\n",
    "            sample_images(epoch,generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Discriminator Model or Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 16)        160       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 99,201\n",
      "Trainable params: 99,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = build_critic()\n",
    "discriminator.compile(loss=wasserstein_loss,\n",
    "            optimizer=RMSprop(lr=0.00005),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = build_dc_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 28, 28, 1)         856193    \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 99201     \n",
      "=================================================================\n",
      "Total params: 955,394\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 99,585\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Noise for generator\n",
    "z_dim = 100\n",
    "z = Input(shape=(z_dim,))\n",
    "img = generator(z)\n",
    "\n",
    "# Fix the discriminator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# Get discriminator output\n",
    "valid = discriminator(img)\n",
    "\n",
    "# Stack discriminator on top of generator\n",
    "gan_model = Model(z, valid)\n",
    "gan_model.compile(loss=wasserstein_loss,\n",
    "    optimizer=RMSprop(lr=0.00005),\n",
    "    metrics=['accuracy'])\n",
    "gan_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train W-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(generator,discriminator,gan_model,epochs=4000, batch_size=64, sample_interval=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "Samples generated after 4000 epochs\n",
    "<img src=\"outputs/w_gan_output.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
