{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional GAN (DC-GAN)\n",
    "\n",
    "Originally proposed by [Radford et al.](https://arxiv.org/pdf/1511.06434.pdf) is their work titled Unsupervised Representation Learning With Deep Convolutions Generative Adversarial Networks. This network uses a basic implementation where generator and discriminator models use convolutional layers, batch normalization and Upsampling.\n",
    "This notebook trains both networks using ADAM optimizer to play the minimax game. We showcase the effectiveness using MNIST digit generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PacktPublishing/Hands-On-Generative-AI-with-Python-and-TensorFlow-2/blob/master/Chapter_6/deep_convolutional_gan.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gan_utils import build_dc_discriminator\n",
    "from gan_utils import build_dc_generator\n",
    "from gan_utils import sample_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN Training Loop\n",
    "- As proposed in the original paper\n",
    "- Train discriminator using a mix of fake and real samples\n",
    "- Calculate discriminator loss\n",
    "- Fix the discriminator and train generator\n",
    "\n",
    "_Note : This is same as Vanilla GAN training_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator=None,discriminator=None,gan_model=None,\n",
    "          epochs=1000, batch_size=128, sample_interval=50,\n",
    "          z_dim=100):\n",
    "    # Load MNIST train samples\n",
    "    (X_train, _), (_, _) = datasets.mnist.load_data()\n",
    "\n",
    "    # Rescale -1 to 1\n",
    "    X_train = X_train / 127.5 - 1\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "    # Prepare GAN output labels\n",
    "    real_y = np.ones((batch_size, 1))\n",
    "    fake_y = np.zeros((batch_size, 1))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # train disriminator\n",
    "        # pick random real samples from X_train\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        real_imgs = X_train[idx]\n",
    "\n",
    "        # pick random noise samples (z) from a normal distribution\n",
    "        noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "        # use generator model to generate output samples\n",
    "        fake_imgs = generator.predict(noise)\n",
    "\n",
    "        # calculate discriminator loss on real samples\n",
    "        disc_loss_real = discriminator.train_on_batch(real_imgs, real_y)\n",
    "        \n",
    "        # calculate discriminator loss on fake samples\n",
    "        disc_loss_fake = discriminator.train_on_batch(fake_imgs, fake_y)\n",
    "        \n",
    "        # overall discriminator loss\n",
    "        discriminator_loss = 0.5 * np.add(disc_loss_real, disc_loss_fake)\n",
    "        \n",
    "        #train generator\n",
    "        # pick random noise samples (z) from a normal distribution\n",
    "        noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "\n",
    "        # use trained discriminator to improve generator\n",
    "        gen_loss = gan_model.train_on_batch(noise, real_y)\n",
    "\n",
    "        # training updates\n",
    "        print (\"%d [Discriminator loss: %f, acc.: %.2f%%] [Generator loss: %f]\" % (epoch, \n",
    "                                                                                   discriminator_loss[0], \n",
    "                                                                                   100*discriminator_loss[1], \n",
    "                                                                                   gen_loss))\n",
    "\n",
    "        # If at save interval => save generated image samples\n",
    "        if epoch % sample_interval == 0:\n",
    "            sample_images(epoch,generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = build_dc_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy',\n",
    "                      optimizer=Adam(0.0001, 0.2),\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator=build_dc_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 28, 28, 1)         856193    \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 1)                 393729    \n",
      "=================================================================\n",
      "Total params: 1,249,922\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 394,113\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Noise for generator\n",
    "z_dim = 100\n",
    "z = Input(shape=(z_dim,))\n",
    "img = generator(z)\n",
    "\n",
    "# Fix the discriminator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# Get discriminator output\n",
    "validity = discriminator(img)\n",
    "\n",
    "# Stack discriminator on top of generator\n",
    "gan_model = Model(z, validity)\n",
    "gan_model.compile(loss='binary_crossentropy', optimizer=Adam(0.0005, 0.5))\n",
    "gan_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(generator,discriminator,gan_model,epochs=2500, batch_size=64, sample_interval=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "Samples generated after 2500 epochs\n",
    "<img src=\"outputs/dc_gan_output.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
