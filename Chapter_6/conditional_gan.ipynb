{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional GAN (C-GAN)\n",
    "\n",
    "Originally proposed by [Mirza et al.](https://arxiv.org/pdf/1411.1784.pdf) is their work titled Conditional Generative Adversarial Nets. This network uses a basic implementation where generator and discriminator models are MLPs with additional inputs for conditioning with class labels.\n",
    "This notebook trains both networks using ADAM optimizer to play the minimax game. We showcase the effectiveness using MNIST digit generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PacktPublishing/Hands-On-Generative-AI-with-Python-and-TensorFlow-2/blob/master/Chapter_6/conditional_gan.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gan_utils import build_conditional_discriminator\n",
    "from gan_utils import build_conditional_generator\n",
    "from gan_utils import sample_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional GAN Training Loop\n",
    "- As proposed in the original paper\n",
    "- Randomly sample class labels as additional input for both discriminator and generator models\n",
    "- Calculate Discriminator loss\n",
    "- Fix the discriminator and calculate GAN/generator loss\n",
    "\n",
    "_Note : This is same as Vanilla GAN training_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator=None,discriminator=None,gan_model=None,\n",
    "          epochs=1000, batch_size=128, sample_interval=50,\n",
    "          z_dim=100):\n",
    "    # Load MNIST train samples\n",
    "    (X_train, y_train), (_, _) = datasets.mnist.load_data()\n",
    "\n",
    "    # Rescale -1 to 1\n",
    "    X_train = X_train / 127.5 - 1\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "    # Prepare GAN output labels\n",
    "    real_y = np.ones((batch_size, 1))\n",
    "    fake_y = np.zeros((batch_size, 1))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # train disriminator\n",
    "        # pick random real samples from X_train\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        real_imgs, labels = X_train[idx], y_train[idx]\n",
    "\n",
    "        # pick random noise samples (z) from a normal distribution\n",
    "        noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "        # use generator model to generate output samples\n",
    "        fake_imgs = generator.predict([noise, labels])\n",
    "\n",
    "        # calculate discriminator loss on real samples\n",
    "        disc_loss_real = discriminator.train_on_batch([real_imgs, labels], real_y)\n",
    "        \n",
    "        # calculate discriminator loss on fake samples\n",
    "        disc_loss_fake = discriminator.train_on_batch([fake_imgs, labels], fake_y)\n",
    "        \n",
    "        # overall discriminator loss\n",
    "        discriminator_loss = 0.5 * np.add(disc_loss_real, disc_loss_fake)\n",
    "        \n",
    "        # train generator\n",
    "        # pick random noise samples (z) from a normal distribution\n",
    "        noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "        \n",
    "        # pick random labels for conditioning\n",
    "        sampled_labels = np.random.randint(0, 10, batch_size).reshape(-1, 1)\n",
    "\n",
    "        # use trained discriminator to improve generator\n",
    "        gen_loss = gan_model.train_on_batch([noise, sampled_labels], real_y)\n",
    "\n",
    "        # training updates\n",
    "        print (\"%d [Discriminator loss: %f, acc.: %.2f%%] [Generator loss: %f]\" % (epoch, \n",
    "                                                                                   discriminator_loss[0], \n",
    "                                                                                   100*discriminator_loss[1], \n",
    "                                                                                   gen_loss))\n",
    "\n",
    "        # If at save interval => save generated image samples\n",
    "        if epoch % sample_interval == 0:\n",
    "            sample_images(epoch,generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 784)       7840        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 784)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 784)          0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 784)          0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          401920      multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          262656      leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          262656      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            513         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 935,585\n",
      "Trainable params: 935,585\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = build_conditional_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy',\n",
    "                      optimizer=Adam(0.0002, 0.5),\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 100)       1000        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 100)          0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 100)          0           input_3[0][0]                    \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          25856       multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 256)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 256)          1024        leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 512)          131584      batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 512)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1024)         525312      leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 1024)         0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1024)         4096        leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 784)          803600      batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 28, 28, 1)    0           dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,492,472\n",
      "Trainable params: 1,489,912\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator=build_conditional_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 28, 28, 1)    1492472     input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model (Model)                   (None, 1)            935585      model_1[1][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,428,057\n",
      "Trainable params: 1,489,912\n",
      "Non-trainable params: 938,145\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Noise for generator\n",
    "z_dim = 100\n",
    "z = Input(shape=(z_dim,))\n",
    "label = Input(shape=(1,))\n",
    "img = generator([z, label])\n",
    "\n",
    "# Fix the discriminator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# Get discriminator output\n",
    "validity = discriminator([img, label])\n",
    "\n",
    "# Stack discriminator on top of generator\n",
    "gan_model = Model([z, label], validity)\n",
    "gan_model.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
    "gan_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Conditional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(generator,discriminator,gan_model,epochs=20000, batch_size=32, sample_interval=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "Samples generated after 2500 epochs\n",
    "<img src=\"outputs/c_gan_output.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
